{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import jieba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip...estimators=20, n_jobs=1, oob_score=False, random_state=5,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pickle.load(open('sa/model','rb'))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordset = set()\n",
    "with open('sa/jieba_dict/stopwords.txt','r',encoding = 'utf-8') as sw:\n",
    "    for line in sw:\n",
    "        stopwordset.add(line.strip('\\n'))\n",
    "        \n",
    "def seg_sent(art):\n",
    "    r = '[’!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]+'  \n",
    "    art = art.strip()\n",
    "    art = re.sub(r, '', art)\n",
    "    l = []\n",
    "    seg_list = list(jieba.cut(art, cut_all = False))\n",
    "    for word in seg_list:\n",
    "        if word not in stopwordset and word != ' ' and word != \"\\n\" and word != \"\\n\\n\":\n",
    "            l.append(word)\n",
    "    corpus = \" \".join(l)\n",
    "    return corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(title):\n",
    "    file = open(title,\"r\",encoding = 'utf-8')\n",
    "\n",
    "    article = file.read()\n",
    "\n",
    "    cp = seg_sent(article)\n",
    "    \n",
    "    result = model.predict([cp])\n",
    "    output = open('file_sa.txt','w')\n",
    "    if result == 0:\n",
    "        print (\"这是一篇负面新闻\")\n",
    "        output.write(\"这是一篇负面新闻\")\n",
    "    else:\n",
    "        print(\"这是一篇正面新闻\")\n",
    "        output.write(\"这是一篇正面新闻\")\n",
    "    print('负面值:\\t\\t','正面值:')\n",
    "    rate = model.predict_proba([cp])\n",
    "    print(rate)\n",
    "    output.write(\"负面值：\"+str(rate[0][0])+\" 正面值： \"+str(rate[0][1]))\n",
    "    return rate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    import tkinter as tk\n",
    "    from tkinter import filedialog\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    main(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
